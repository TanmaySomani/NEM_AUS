{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca0cee0-57b6-4e05-b3ed-22b1cd749c7a",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684e781a-bc29-4d02-857e-bee3b08ffd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "demand_actual = pd.read_csv('demand_actual_qld.csv')\n",
    "demand_forecast = pd.read_csv('demand_forecast_qld.csv')\n",
    "interconnections = pd.read_csv('interconnections.csv')\n",
    "prices_qld = pd.read_csv('prices_qld.csv')\n",
    "rooftop_solar = pd.read_csv('rooftop_solar_qld.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe63e9c-2cf0-4aea-8ec1-f0ddb4384197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44911 entries, 0 to 44910\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   date_time           44911 non-null  object\n",
      " 1   LASTCHANGED         44911 non-null  object\n",
      " 2   REGIONID            44911 non-null  object\n",
      " 3   OPERATIONAL_DEMAND  44911 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45313 entries, 0 to 45312\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   date_time                 45313 non-null  object \n",
      " 1   LASTCHANGED               45313 non-null  object \n",
      " 2   REGIONID                  45313 non-null  object \n",
      " 3   LOAD_DATE                 45313 non-null  object \n",
      " 4   OPERATIONAL_DEMAND_POE10  45313 non-null  float64\n",
      " 5   OPERATIONAL_DEMAND_POE50  45313 non-null  int64  \n",
      " 6   OPERATIONAL_DEMAND_POE90  45313 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 2.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 868620 entries, 0 to 868619\n",
      "Data columns (total 22 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   SETTLEMENTDATE                 868620 non-null  object \n",
      " 1   RUNNO                          868620 non-null  int64  \n",
      " 2   INTERCONNECTORID               868620 non-null  object \n",
      " 3   DISPATCHINTERVAL               868620 non-null  float64\n",
      " 4   INTERVENTION                   868620 non-null  int64  \n",
      " 5   METEREDMWFLOW                  868620 non-null  float64\n",
      " 6   MWFLOW                         868620 non-null  float64\n",
      " 7   MWLOSSES                       868620 non-null  float64\n",
      " 8   MARGINALVALUE                  868620 non-null  float64\n",
      " 9   VIOLATIONDEGREE                868620 non-null  int64  \n",
      " 10  LASTCHANGED                    868620 non-null  object \n",
      " 11  EXPORTLIMIT                    868620 non-null  float64\n",
      " 12  IMPORTLIMIT                    868620 non-null  float64\n",
      " 13  MARGINALLOSS                   868620 non-null  float64\n",
      " 14  EXPORTGENCONID                 868620 non-null  object \n",
      " 15  IMPORTGENCONID                 868620 non-null  object \n",
      " 16  FCASEXPORTLIMIT                868620 non-null  float64\n",
      " 17  FCASIMPORTLIMIT                868620 non-null  float64\n",
      " 18  LOCAL_PRICE_ADJUSTMENT_EXPORT  868620 non-null  float64\n",
      " 19  LOCALLY_CONSTRAINED_EXPORT     868620 non-null  int64  \n",
      " 20  LOCAL_PRICE_ADJUSTMENT_IMPORT  868620 non-null  float64\n",
      " 21  LOCALLY_CONSTRAINED_IMPORT     868620 non-null  int64  \n",
      "dtypes: float64(12), int64(5), object(5)\n",
      "memory usage: 145.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 269452 entries, 0 to 269451\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  269452 non-null  int64  \n",
      " 1   date_time   269452 non-null  object \n",
      " 2   REGIONID    269452 non-null  object \n",
      " 3   RRP         269452 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 8.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89751 entries, 0 to 89750\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   INTERVAL_DATETIME  89751 non-null  object \n",
      " 1   TYPE               89751 non-null  object \n",
      " 2   REGIONID           89751 non-null  object \n",
      " 3   POWER              89746 non-null  float64\n",
      " 4   QI                 89751 non-null  float64\n",
      " 5   LASTCHANGED        89751 non-null  object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about each dataset to understand its structure\n",
    "demand_actual_info = demand_actual.info()\n",
    "demand_forecast_info = demand_forecast.info()\n",
    "interconnections_info = interconnections.info()\n",
    "prices_qld_info = prices_qld.info()\n",
    "rooftop_solar_info = rooftop_solar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b885895-a6c9-45f9-9ab0-72987ff3488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of each dataset to get an idea of the data\n",
    "demand_actual_head = demand_actual.head()\n",
    "demand_forecast_head = demand_forecast.head()\n",
    "interconnections_head = interconnections.head()\n",
    "prices_qld_head = prices_qld.head()\n",
    "rooftop_solar_head = rooftop_solar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c274d48b-2f33-4bbf-b048-989057bc2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date_time' column to datetime in all datasets\n",
    "demand_actual['date_time'] = pd.to_datetime(demand_actual['date_time'])\n",
    "demand_forecast['date_time'] = pd.to_datetime(demand_forecast['date_time'])\n",
    "prices_qld['date_time'] = pd.to_datetime(prices_qld['date_time'])\n",
    "rooftop_solar['INTERVAL_DATETIME'] = pd.to_datetime(rooftop_solar['INTERVAL_DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f321e9-40ef-449f-845c-af0b211dc460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       "              date_time          LASTCHANGED REGIONID  OPERATIONAL_DEMAND\n",
       " 0  2022-01-01 00:00:00  2022-01-01 00:00:02     QLD1                6133\n",
       " 1  2022-01-01 00:30:00  2022-01-01 00:30:01     QLD1                5968\n",
       " 2  2022-01-01 01:00:00  2022-01-01 01:00:01     QLD1                5877\n",
       " 3  2022-01-01 01:30:00  2022-01-01 01:30:02     QLD1                5798\n",
       " 4  2022-01-01 02:00:00  2022-01-01 02:00:01     QLD1                5682,\n",
       "              date_time          LASTCHANGED REGIONID            LOAD_DATE  \\\n",
       " 0  2022-01-01 00:00:00  2021-12-31 22:57:23     QLD1  2021-12-31 22:57:23   \n",
       " 1  2022-01-01 00:30:00  2021-12-31 23:57:28     QLD1  2021-12-31 23:57:28   \n",
       " 2  2022-01-01 01:00:00  2022-01-01 00:27:28     QLD1  2022-01-01 00:27:28   \n",
       " 3  2022-01-01 01:30:00  2022-01-01 00:57:27     QLD1  2022-01-01 00:57:27   \n",
       " 4  2022-01-01 02:00:00  2022-01-01 01:27:28     QLD1  2022-01-01 01:27:28   \n",
       " \n",
       "    OPERATIONAL_DEMAND_POE10  OPERATIONAL_DEMAND_POE50  \\\n",
       " 0                    6226.0                      6129   \n",
       " 1                    6030.0                      5935   \n",
       " 2                    5979.0                      5886   \n",
       " 3                    5906.0                      5813   \n",
       " 4                    5773.0                      5682   \n",
       " \n",
       "    OPERATIONAL_DEMAND_POE90  \n",
       " 0                    6031.0  \n",
       " 1                    5841.0  \n",
       " 2                    5792.0  \n",
       " 3                    5720.0  \n",
       " 4                    5592.0  ,\n",
       "         SETTLEMENTDATE  RUNNO INTERCONNECTORID  DISPATCHINTERVAL  \\\n",
       " 0  2022-11-29 05:50:00      1        N-Q-MNSP1      2.022113e+10   \n",
       " 1  2022-11-29 05:50:00      1        NSW1-QLD1      2.022113e+10   \n",
       " 2  2022-11-29 05:50:00      1        T-V-MNSP1      2.022113e+10   \n",
       " 3  2022-11-29 05:50:00      1        V-S-MNSP1      2.022113e+10   \n",
       " 4  2022-11-29 05:50:00      1             V-SA      2.022113e+10   \n",
       " \n",
       "    INTERVENTION  METEREDMWFLOW     MWFLOW  MWLOSSES  MARGINALVALUE  \\\n",
       " 0             0      -20.10000  -20.30000  -0.77525            0.0   \n",
       " 1             0      143.29990  110.82281   3.00815            0.0   \n",
       " 2             0      330.20001  323.59037   9.61581            0.0   \n",
       " 3             0       99.00000   99.00000   2.81972            0.0   \n",
       " 4             0      287.99155  326.15544  19.70758            0.0   \n",
       " \n",
       "    VIOLATIONDEGREE  ... IMPORTLIMIT  MARGINALLOSS     EXPORTGENCONID  \\\n",
       " 0                0  ...   -22.30000       1.00929        N_X_MBTE_3A   \n",
       " 1                0  ... -1172.89068       1.03722    NQ_600_DYN_TEST   \n",
       " 2                0  ...   201.46790       1.06228             TV_350   \n",
       " 3                0  ...    19.00000       1.13504  S>NIL_MHNW1_MHNW2   \n",
       " 4                0  ...  -470.00000       1.12257    V:S_600_HY_TEST   \n",
       " \n",
       "        IMPORTGENCONID FCASEXPORTLIMIT FCASIMPORTLIMIT  \\\n",
       " 0         N_X_MBTE_3B        -20.3000           -22.3   \n",
       " 1       Q^^N_NIL_SRAR       2204.0000         -2478.0   \n",
       " 2  F_MAIN++APD_TL_L60        594.0000          -478.0   \n",
       " 3         SVML_ROC_80        171.5075            19.0   \n",
       " 4      S:V_PA_SVC_470        950.0000          -850.0   \n",
       " \n",
       "    LOCAL_PRICE_ADJUSTMENT_EXPORT  LOCALLY_CONSTRAINED_EXPORT  \\\n",
       " 0                          -4.53                           2   \n",
       " 1                           0.00                           0   \n",
       " 2                           0.00                           0   \n",
       " 3                           0.00                           0   \n",
       " 4                           0.00                           0   \n",
       " \n",
       "    LOCAL_PRICE_ADJUSTMENT_IMPORT  LOCALLY_CONSTRAINED_IMPORT  \n",
       " 0                            0.0                           0  \n",
       " 1                            0.0                           0  \n",
       " 2                            0.0                           0  \n",
       " 3                            0.0                           0  \n",
       " 4                            0.0                           0  \n",
       " \n",
       " [5 rows x 22 columns],\n",
       "    Unnamed: 0            date_time REGIONID     RRP\n",
       " 0           2  2022-01-01 00:00:00     QLD1  118.73\n",
       " 1           7  2022-01-01 00:05:00     QLD1  118.73\n",
       " 2          12  2022-01-01 00:10:00     QLD1  119.10\n",
       " 3          17  2022-01-01 00:15:00     QLD1  118.73\n",
       " 4          22  2022-01-01 00:20:00     QLD1  109.20,\n",
       "      INTERVAL_DATETIME         TYPE REGIONID  POWER   QI          LASTCHANGED\n",
       " 0  2022-01-01 00:00:00  MEASUREMENT     QLD1    0.0  1.0  2022-01-01 00:19:44\n",
       " 1  2022-01-01 00:00:00    SATELLITE     QLD1    0.0  1.0  2022-01-01 00:20:29\n",
       " 2  2022-01-01 00:30:00  MEASUREMENT     QLD1    0.0  1.0  2022-01-01 00:49:43\n",
       " 3  2022-01-01 00:30:00    SATELLITE     QLD1    0.0  1.0  2022-01-01 00:50:23\n",
       " 4  2022-01-01 01:00:00  MEASUREMENT     QLD1    0.0  1.0  2022-01-01 01:19:46)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.merge(demand_actual, demand_forecast[['date_time', 'OPERATIONAL_DEMAND_POE50']], \n",
    "                       on='date_time', how='left')\n",
    "merged_data = pd.merge(merged_data, prices_qld[['date_time', 'RRP']], on='date_time', how='left')\n",
    "merged_data = pd.merge(merged_data, rooftop_solar[['INTERVAL_DATETIME', 'POWER']], \n",
    "                       left_on='date_time', right_on='INTERVAL_DATETIME', how='left')\n",
    "\n",
    "(demand_actual_info, demand_forecast_info, interconnections_info, prices_qld_info, rooftop_solar_info,\n",
    " demand_actual_head, demand_forecast_head, interconnections_head, prices_qld_head, rooftop_solar_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254cfe37-0e9e-4666-a8e9-0aa04b8664bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>LASTCHANGED</th>\n",
       "      <th>REGIONID</th>\n",
       "      <th>OPERATIONAL_DEMAND</th>\n",
       "      <th>OPERATIONAL_DEMAND_POE50</th>\n",
       "      <th>RRP</th>\n",
       "      <th>INTERVAL_DATETIME</th>\n",
       "      <th>POWER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2022-01-01 00:00:02</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>6133</td>\n",
       "      <td>6129</td>\n",
       "      <td>118.73</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2022-01-01 00:00:02</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>6133</td>\n",
       "      <td>6129</td>\n",
       "      <td>118.73</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 00:30:00</td>\n",
       "      <td>2022-01-01 00:30:01</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>5968</td>\n",
       "      <td>5935</td>\n",
       "      <td>118.73</td>\n",
       "      <td>2022-01-01 00:30:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 00:30:00</td>\n",
       "      <td>2022-01-01 00:30:01</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>5968</td>\n",
       "      <td>5935</td>\n",
       "      <td>118.73</td>\n",
       "      <td>2022-01-01 00:30:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>2022-01-01 01:00:01</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>5877</td>\n",
       "      <td>5886</td>\n",
       "      <td>91.10</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89750</th>\n",
       "      <td>2024-07-24 14:00:00</td>\n",
       "      <td>2024-07-24 14:00:02</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>4957</td>\n",
       "      <td>5001</td>\n",
       "      <td>-9.70</td>\n",
       "      <td>2024-07-24 14:00:00</td>\n",
       "      <td>2496.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89751</th>\n",
       "      <td>2024-07-24 14:00:00</td>\n",
       "      <td>2024-07-24 14:00:02</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>4957</td>\n",
       "      <td>5001</td>\n",
       "      <td>-9.70</td>\n",
       "      <td>2024-07-24 14:00:00</td>\n",
       "      <td>2223.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89752</th>\n",
       "      <td>2024-07-24 14:30:00</td>\n",
       "      <td>2024-07-24 14:30:02</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>5028</td>\n",
       "      <td>5124</td>\n",
       "      <td>29.73</td>\n",
       "      <td>2024-07-24 14:30:00</td>\n",
       "      <td>2362.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89753</th>\n",
       "      <td>2024-07-24 14:30:00</td>\n",
       "      <td>2024-07-24 14:30:02</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>5028</td>\n",
       "      <td>5124</td>\n",
       "      <td>29.73</td>\n",
       "      <td>2024-07-24 14:30:00</td>\n",
       "      <td>2049.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89754</th>\n",
       "      <td>2024-07-24 15:00:00</td>\n",
       "      <td>2024-07-24 15:00:02</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>5169</td>\n",
       "      <td>5230</td>\n",
       "      <td>44.94</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89755 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_time          LASTCHANGED REGIONID  OPERATIONAL_DEMAND  \\\n",
       "0     2022-01-01 00:00:00  2022-01-01 00:00:02     QLD1                6133   \n",
       "1     2022-01-01 00:00:00  2022-01-01 00:00:02     QLD1                6133   \n",
       "2     2022-01-01 00:30:00  2022-01-01 00:30:01     QLD1                5968   \n",
       "3     2022-01-01 00:30:00  2022-01-01 00:30:01     QLD1                5968   \n",
       "4     2022-01-01 01:00:00  2022-01-01 01:00:01     QLD1                5877   \n",
       "...                   ...                  ...      ...                 ...   \n",
       "89750 2024-07-24 14:00:00  2024-07-24 14:00:02     QLD1                4957   \n",
       "89751 2024-07-24 14:00:00  2024-07-24 14:00:02     QLD1                4957   \n",
       "89752 2024-07-24 14:30:00  2024-07-24 14:30:02     QLD1                5028   \n",
       "89753 2024-07-24 14:30:00  2024-07-24 14:30:02     QLD1                5028   \n",
       "89754 2024-07-24 15:00:00  2024-07-24 15:00:02     QLD1                5169   \n",
       "\n",
       "       OPERATIONAL_DEMAND_POE50     RRP   INTERVAL_DATETIME     POWER  \n",
       "0                          6129  118.73 2022-01-01 00:00:00     0.000  \n",
       "1                          6129  118.73 2022-01-01 00:00:00     0.000  \n",
       "2                          5935  118.73 2022-01-01 00:30:00     0.000  \n",
       "3                          5935  118.73 2022-01-01 00:30:00     0.000  \n",
       "4                          5886   91.10 2022-01-01 01:00:00     0.000  \n",
       "...                         ...     ...                 ...       ...  \n",
       "89750                      5001   -9.70 2024-07-24 14:00:00  2496.204  \n",
       "89751                      5001   -9.70 2024-07-24 14:00:00  2223.449  \n",
       "89752                      5124   29.73 2024-07-24 14:30:00  2362.011  \n",
       "89753                      5124   29.73 2024-07-24 14:30:00  2049.101  \n",
       "89754                      5230   44.94                 NaT       NaN  \n",
       "\n",
       "[89755 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe15cb5-59b9-46d6-82c9-011e9ec64a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant columns\n",
    "merged_data.drop(columns=['LASTCHANGED', 'REGIONID', 'INTERVAL_DATETIME'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd95199d-9aad-49fd-ba28-dde7b7d7e3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time                   0\n",
       "OPERATIONAL_DEMAND          0\n",
       "OPERATIONAL_DEMAND_POE50    0\n",
       "RRP                         4\n",
       "POWER                       9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1a9bc67-9b76-4376-b44e-3843d8767729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0t/69p0vkss0r96r21y27qx9pgm0000gn/T/ipykernel_16956/658276246.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data['RRP'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/0t/69p0vkss0r96r21y27qx9pgm0000gn/T/ipykernel_16956/658276246.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data['RRP'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/0t/69p0vkss0r96r21y27qx9pgm0000gn/T/ipykernel_16956/658276246.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_data['POWER'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/0t/69p0vkss0r96r21y27qx9pgm0000gn/T/ipykernel_16956/658276246.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data['POWER'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "merged_data['RRP'].fillna(method='ffill', inplace=True)\n",
    "merged_data['POWER'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4199c5ad-29f9-4c27-8bf5-db097022a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time                   0\n",
       "OPERATIONAL_DEMAND          0\n",
       "OPERATIONAL_DEMAND_POE50    0\n",
       "RRP                         0\n",
       "POWER                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3802e69d-dc72-48c6-b122-36837add8454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0t/69p0vkss0r96r21y27qx9pgm0000gn/T/ipykernel_16956/1695385500.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data.fillna(method='bfill', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>OPERATIONAL_DEMAND</th>\n",
       "      <th>OPERATIONAL_DEMAND_POE50</th>\n",
       "      <th>RRP</th>\n",
       "      <th>POWER</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>demand_lag_1</th>\n",
       "      <th>demand_lag_3</th>\n",
       "      <th>price_lag_1</th>\n",
       "      <th>price_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>6133</td>\n",
       "      <td>6129</td>\n",
       "      <td>118.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6133.0</td>\n",
       "      <td>6133.0</td>\n",
       "      <td>118.73</td>\n",
       "      <td>118.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>6133</td>\n",
       "      <td>6129</td>\n",
       "      <td>118.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6133.0</td>\n",
       "      <td>6133.0</td>\n",
       "      <td>118.73</td>\n",
       "      <td>118.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 00:30:00</td>\n",
       "      <td>5968</td>\n",
       "      <td>5935</td>\n",
       "      <td>118.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6133.0</td>\n",
       "      <td>6133.0</td>\n",
       "      <td>118.73</td>\n",
       "      <td>118.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 00:30:00</td>\n",
       "      <td>5968</td>\n",
       "      <td>5935</td>\n",
       "      <td>118.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5968.0</td>\n",
       "      <td>6133.0</td>\n",
       "      <td>118.73</td>\n",
       "      <td>118.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>5877</td>\n",
       "      <td>5886</td>\n",
       "      <td>91.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5968.0</td>\n",
       "      <td>6133.0</td>\n",
       "      <td>118.73</td>\n",
       "      <td>118.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_time  OPERATIONAL_DEMAND  OPERATIONAL_DEMAND_POE50     RRP  \\\n",
       "0 2022-01-01 00:00:00                6133                      6129  118.73   \n",
       "1 2022-01-01 00:00:00                6133                      6129  118.73   \n",
       "2 2022-01-01 00:30:00                5968                      5935  118.73   \n",
       "3 2022-01-01 00:30:00                5968                      5935  118.73   \n",
       "4 2022-01-01 01:00:00                5877                      5886   91.10   \n",
       "\n",
       "   POWER  day_of_week  hour  demand_lag_1  demand_lag_3  price_lag_1  \\\n",
       "0    0.0            5     0        6133.0        6133.0       118.73   \n",
       "1    0.0            5     0        6133.0        6133.0       118.73   \n",
       "2    0.0            5     0        6133.0        6133.0       118.73   \n",
       "3    0.0            5     0        5968.0        6133.0       118.73   \n",
       "4    0.0            5     1        5968.0        6133.0       118.73   \n",
       "\n",
       "   price_lag_3  \n",
       "0       118.73  \n",
       "1       118.73  \n",
       "2       118.73  \n",
       "3       118.73  \n",
       "4       118.73  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Engineering: Adding time-based features\n",
    "merged_data['day_of_week'] = merged_data['date_time'].dt.dayofweek\n",
    "merged_data['hour'] = merged_data['date_time'].dt.hour\n",
    "\n",
    "# Lagged Features for better prediction of prices (lag by 1 and 3 intervals)\n",
    "merged_data['demand_lag_1'] = merged_data['OPERATIONAL_DEMAND'].shift(1)\n",
    "merged_data['demand_lag_3'] = merged_data['OPERATIONAL_DEMAND'].shift(3)\n",
    "merged_data['price_lag_1'] = merged_data['RRP'].shift(1)\n",
    "merged_data['price_lag_3'] = merged_data['RRP'].shift(3)\n",
    "\n",
    "# Handling missing values created by lagging (just as an example, can be imputed differently)\n",
    "merged_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Display the first few rows of the dataset to check new features\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee1b91-b250-4a7f-80c8-b32135a758f2",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "201ab465-fa5d-48c3-8bc6-f01327a7c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (71804, 9)\n",
      "X_test shape: (17951, 9)\n",
      "y_train shape: (71804,)\n",
      "y_test shape: (17951,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming merged_data is the full dataset, and we are focusing on certain columns\n",
    "# Features and Target selection\n",
    "X = merged_data[['OPERATIONAL_DEMAND', 'OPERATIONAL_DEMAND_POE50', 'POWER', \n",
    "                 'day_of_week', 'hour', 'demand_lag_1', 'demand_lag_3', \n",
    "                 'price_lag_1', 'price_lag_3']]  # Features\n",
    "y = merged_data['RRP']  # Target (Electricity Price)\n",
    "\n",
    "# Step 1: Split the dataset sequentially for training and testing\n",
    "# Example: Use 80% of the data for training and the remaining 20% for testing\n",
    "train_size = int(0.8 * len(X))\n",
    "\n",
    "# Sequential Train-Test Split\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Display the shape of the datasets to verify the split\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff1e9d-a5bf-44a5-9c07-1bb68dc128b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 23:19:58.211172: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-09-30 23:19:58.211232: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2024-09-30 23:19:58.211239: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "2024-09-30 23:19:58.211264: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-30 23:19:58.211278: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/opt/anaconda3/envs/ml-env/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-09-30 23:19:58.685267: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 16ms/step - loss: 7.3172e-04 - mean_absolute_error: 0.0099 - val_loss: 2.0342e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 2/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 16ms/step - loss: 7.1418e-05 - mean_absolute_error: 0.0039 - val_loss: 2.0199e-05 - val_mean_absolute_error: 0.0026\n",
      "Epoch 3/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 16ms/step - loss: 7.4864e-05 - mean_absolute_error: 0.0039 - val_loss: 7.9471e-06 - val_mean_absolute_error: 0.0020\n",
      "Epoch 4/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 16ms/step - loss: 2.8972e-05 - mean_absolute_error: 0.0024 - val_loss: 4.0584e-06 - val_mean_absolute_error: 0.0013\n",
      "Epoch 5/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 16ms/step - loss: 2.2676e-05 - mean_absolute_error: 0.0020 - val_loss: 6.5525e-06 - val_mean_absolute_error: 0.0015\n",
      "Epoch 6/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 16ms/step - loss: 2.4978e-05 - mean_absolute_error: 0.0022 - val_loss: 2.1090e-05 - val_mean_absolute_error: 0.0020\n",
      "Epoch 7/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 17ms/step - loss: 1.9938e-05 - mean_absolute_error: 0.0018 - val_loss: 1.8268e-05 - val_mean_absolute_error: 0.0019\n",
      "Epoch 8/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 16ms/step - loss: 1.9537e-05 - mean_absolute_error: 0.0019 - val_loss: 4.0898e-06 - val_mean_absolute_error: 5.9533e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 16ms/step - loss: 1.4036e-05 - mean_absolute_error: 0.0017 - val_loss: 3.9597e-06 - val_mean_absolute_error: 6.9335e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 17ms/step - loss: 2.1423e-05 - mean_absolute_error: 0.0017 - val_loss: 3.3027e-06 - val_mean_absolute_error: 0.0011\n",
      "Epoch 11/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 16ms/step - loss: 1.2203e-05 - mean_absolute_error: 0.0014 - val_loss: 9.2758e-06 - val_mean_absolute_error: 0.0023\n",
      "Epoch 12/50\n",
      "\u001b[1m3590/3590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 16ms/step - loss: 1.0010e-05 - mean_absolute_error: 0.0013 - val_loss: 2.9407e-06 - val_mean_absolute_error: 0.0013\n",
      "Epoch 13/50\n",
      "\u001b[1m1525/3590\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 15ms/step - loss: 9.6532e-06 - mean_absolute_error: 0.0013"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, LSTM, Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming merged_data is the full dataset with relevant columns\n",
    "X = merged_data[['OPERATIONAL_DEMAND', 'OPERATIONAL_DEMAND_POE50', 'POWER', \n",
    "                 'day_of_week', 'hour', 'demand_lag_1', 'demand_lag_3', \n",
    "                 'price_lag_1', 'price_lag_3']]  # Features\n",
    "y = merged_data['RRP']  # Target (Electricity Price)\n",
    "\n",
    "# Step 1: Time-Series Train-Test Split (80% Train, 20% Test)\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Step 2: Feature and Target Scaling\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Step 3: Define the time_steps (lookback period)\n",
    "time_steps = 3\n",
    "\n",
    "# Step 4: Create lookback data (features and target)\n",
    "def create_lookback(data, time_steps):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        Xs.append(data[i:(i + time_steps)])\n",
    "        ys.append(data[i + time_steps, -1])  # Only append the target value (last column)\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# Step 5: Create lookback for both train and test\n",
    "X_train_rnn_lstm, y_train_rnn_lstm = create_lookback(X_train_scaled, time_steps)\n",
    "X_test_rnn_lstm, y_test_rnn_lstm = create_lookback(X_test_scaled, time_steps)\n",
    "\n",
    "# Step 6: Build, compile, and train the RNN + LSTM model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=50, return_sequences=True, input_shape=(X_train_rnn_lstm.shape[1], X_train_rnn_lstm.shape[2])))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))  # Single output for the electricity price\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_rnn_lstm, y_train_rnn_lstm, epochs=50, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# Step 7: Predict on the test set\n",
    "y_pred_rnn_lstm_scaled = model.predict(X_test_rnn_lstm)\n",
    "\n",
    "# Step 8: Inverse scale the predictions and actual values\n",
    "y_pred_rnn_lstm_rescaled = scaler_y.inverse_transform(y_pred_rnn_lstm_scaled)\n",
    "y_test_rnn_lstm_rescaled = scaler_y.inverse_transform(y_test_rnn_lstm.reshape(-1, 1))  # Reshape to ensure 2D\n",
    "\n",
    "# Step 9: Evaluate the model using MAE\n",
    "mae_rnn_lstm = mean_absolute_error(y_test_rnn_lstm_rescaled, y_pred_rnn_lstm_rescaled)\n",
    "print(f'MAE from RNN + LSTM: {mae_rnn_lstm}')\n",
    "\n",
    "# Function to find the most optimal epoch based on validation loss\n",
    "def find_optimal_epoch(history):\n",
    "    val_losses = history.history['val_loss']\n",
    "    optimal_epoch = np.argmin(val_losses) + 1  # Adding 1 because epochs start from 1\n",
    "    print(f'The most optimal epoch based on validation loss is: Epoch {optimal_epoch} with validation loss: {val_losses[optimal_epoch-1]:.4f}')\n",
    "\n",
    "# Step 10: Call the function to find and print the most optimal epoch\n",
    "find_optimal_epoch(history)\n",
    "\n",
    "# Step 11: Plot Loss and MAE\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Training and Validation MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mean_absolute_error'], label='Training MAE')\n",
    "plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\n",
    "plt.title('Model Mean Absolute Error (MAE)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e814c-e3f5-45a3-8602-c12d05ad0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SMAPE calculation function\n",
    "def calculate_smape(y_true, y_pred):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    smape = np.mean(np.abs(y_true - y_pred) / denominator) * 100\n",
    "    return smape\n",
    "\n",
    "# Step 1: Calculate SMAPE and SMAPE-based Accuracy\n",
    "smape_rnn_lstm = calculate_smape(y_test_rnn_lstm_rescaled, y_pred_rnn_lstm_rescaled)\n",
    "accuracy_smape_rnn_lstm = 100 - smape_rnn_lstm\n",
    "\n",
    "# Print SMAPE and Accuracy\n",
    "print(f'SMAPE: {smape_rnn_lstm:.2f}%')\n",
    "print(f'Accuracy (SMAPE-based): {accuracy_smape_rnn_lstm:.2f}%')\n",
    "\n",
    "# Step 2: Plot Actual vs Predicted Prices (Line Plot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(y_test_rnn_lstm_rescaled, label='Actual Prices', color='blue')\n",
    "plt.plot(y_pred_rnn_lstm_rescaled, label='Predicted Prices', color='red', linestyle='--')\n",
    "plt.title(f\"Actual vs Predicted Prices (SMAPE-based Accuracy: {accuracy_smape_rnn_lstm:.2f}%)\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Electricity Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Scatter Plot for Actual vs Predicted Prices\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test_rnn_lstm_rescaled, y_pred_rnn_lstm_rescaled, alpha=0.5, color='green')\n",
    "plt.title(f\"Scatter Plot: Actual vs Predicted Prices (SMAPE-based Accuracy: {accuracy_smape_rnn_lstm:.2f}%)\")\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "\n",
    "# Line of perfect prediction (for reference)\n",
    "plt.plot([y_test_rnn_lstm_rescaled.min(), y_test_rnn_lstm_rescaled.max()], \n",
    "         [y_test_rnn_lstm_rescaled.min(), y_test_rnn_lstm_rescaled.max()], color='red', linewidth=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0acc5c-6b72-4e4a-a2db-6f108e31233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Experiment with different lookback periods (time_steps)\n",
    "# for time_steps in [1, 3, 5, 10]:\n",
    "#     # Prepare the data with the current lookback\n",
    "#     X_train_rnn_lstm, y_train_rnn_lstm = create_lookback(X_train_scaled, time_steps)\n",
    "#     X_test_rnn_lstm, y_test_rnn_lstm = create_lookback(X_test_scaled, time_steps)\n",
    "    \n",
    "#     # Build the model (same as before)\n",
    "#     model = Sequential()\n",
    "#     model.add(SimpleRNN(units=50, return_sequences=True, input_shape=(X_train_rnn_lstm.shape[1], X_train_rnn_lstm.shape[2])))\n",
    "#     model.add(LSTM(units=50))\n",
    "#     model.add(Dense(1))\n",
    "#     model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    \n",
    "#     # Train the model\n",
    "#     history = model.fit(X_train_rnn_lstm, y_train_rnn_lstm, epochs=20, batch_size=32, validation_split=0.2)\n",
    "    \n",
    "#     # Predict and evaluate the model\n",
    "#     y_pred_rnn_lstm_scaled = model.predict(X_test_rnn_lstm)\n",
    "#     y_pred_rnn_lstm_rescaled = scaler_y.inverse_transform(y_pred_rnn_lstm_scaled)\n",
    "#     y_test_rnn_lstm_rescaled = scaler_y.inverse_transform(y_test_rnn_lstm.reshape(-1, 1))\n",
    "    \n",
    "#     mae_rnn_lstm = mean_absolute_error(y_test_rnn_lstm_rescaled, y_pred_rnn_lstm_rescaled)\n",
    "#     print(f'Time Steps: {time_steps}, MAE: {mae_rnn_lstm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a7b0071-7d8e-45c9-b849-fa17b426a52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 9 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(predicted_price[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Extract the scalar price from the array\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Prepare the new input sequence for the next prediction\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Shift the sequence and add the predicted price as the next input\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     new_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_sequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpredicted_price_scaled\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     last_sequence \u001b[38;5;241m=\u001b[39m new_sequence\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Convert the predictions to a numpy array\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.10/site-packages/numpy/lib/function_base.py:5618\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5616\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[1;32m   5617\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 9 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assume the model is already trained and you have the scaler and test data\n",
    "# Set the number of time steps to predict (e.g., for 30 days with hourly prices)\n",
    "n_steps = 30 * 24  # For hourly predictions for the next month\n",
    "\n",
    "# Get the last sequence from the test set (to start predicting future prices)\n",
    "last_sequence = X_test_rnn_lstm[-1:]  # Shape should be (1, time_steps, num_features)\n",
    "\n",
    "# Prepare to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Iteratively predict each next time step (for n_steps ahead)\n",
    "for _ in range(n_steps):\n",
    "    # Predict the next time step\n",
    "    predicted_price_scaled = model.predict(last_sequence)\n",
    "\n",
    "    # Inverse transform the scaled predicted price to get the actual price\n",
    "    predicted_price = scaler_y.inverse_transform(predicted_price_scaled)\n",
    "\n",
    "    # Store the prediction\n",
    "    predictions.append(predicted_price[0, 0])  # Extract the scalar price from the array\n",
    "\n",
    "    # Prepare the new input sequence for the next prediction\n",
    "    # Shift the sequence and add the predicted price as the next input\n",
    "    new_sequence = np.append(last_sequence[:, 1:, :], [[predicted_price_scaled[0]]], axis=1)\n",
    "    last_sequence = new_sequence\n",
    "\n",
    "# Convert the predictions to a numpy array\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Plot the predicted prices for the next month\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(predictions, label='Predicted Prices for Next Month')\n",
    "plt.title('Electricity Price Predictions for the Next Month')\n",
    "plt.xlabel('Time (Hourly Intervals)')\n",
    "plt.ylabel('Electricity Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b7a5e-2bdf-4992-889c-7bfa8c5130c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6098a-3759-4fef-aaf2-a4f62155b97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce362444-79d8-4600-98fc-7b5d7ffea127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89465ff6-5b58-4668-b621-ffbf1368aace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acbb8b0-cc3e-4ab5-aa12-e6d7ec4d7aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e4808-d53b-47a3-8eb9-dbc38fc3ed2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c45970-630e-450b-ad0d-c4691d587047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8365c24e-4115-4dfd-b19d-29548b049bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6db249-872d-42cf-b05f-5aa41f0d81a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3721e1-0793-4e08-af19-2e62c53cb665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928392b7-0184-4c18-8ae2-6c34d358bead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aaf146-defb-4de5-8766-1f1d5273540b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b97cc99-007f-43c4-8691-5b99882708f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
